{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lucem_illud\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(load_file_path = 'database/content_analysis.csv', save_file_path = 'database/cleaned_content_analysis.csv'):\n",
    "    '''\n",
    "    This function cleans a pandas DataFrame.\n",
    "    \n",
    "    Inputs:\n",
    "        load_file_path: file path to load original CSV file\n",
    "        save_file_path: file path to save cleaned CSV file\n",
    "    '''\n",
    "    \n",
    "    # load the CSV file to a DataFrame\n",
    "    df = pd.read_csv(load_file_path, index_col=0)\n",
    "    \n",
    "    # drop columns \n",
    "    df.drop(['paper_url', 'publication_date', 'paper_yearly_citations', 'author_url', 'author_total_citations', 'h_index', 'interests', \n",
    "             'directorate', 'division', 'effective_date', 'expiration_date', 'award_title', 'award_abstract'], axis=1, inplace=True)\n",
    "\n",
    "    # reorder columns\n",
    "    df = df[['first_name', 'middle_name', 'last_name', 'email', 'institution', 'award_year', 'award_amount', 'paper_title', 'journal', \n",
    "             'publication_year', 'coauthors', 'paper_abstract', 'paper_total_citations', 'citation_2001', 'citation_2002', 'citation_2003', \n",
    "             'citation_2004', 'citation_2005', 'citation_2006', 'citation_2007', 'citation_2008', 'citation_2009', 'citation_2010', \n",
    "             'citation_2011', 'citation_2012', 'citation_2013', 'citation_2014', 'citation_2015', 'citation_2016', 'citation_2017', \n",
    "             'citation_2018', 'citation_2019', 'citation_2020', 'citation_2021', 'citation_2022', 'citation_2023', 'citation_2024']]\n",
    "\n",
    "    # convert email names to lowercase\n",
    "    df['email'] = df['email'].str.lower()\n",
    "    \n",
    "    # convert institution names to lowercase\n",
    "    df['institution'] = df['institution'].str.lower()\n",
    "    \n",
    "    # replace NaN values with empty lists in 'coauthors'\n",
    "    df['coauthors'] = df['coauthors'].apply(lambda x: [] if pd.isna(x) else x)\n",
    "\n",
    "    # convert each row in 'coauthors' to a list of authors\n",
    "    df['coauthors'] = df['coauthors'].apply(lambda x: x if isinstance(x, list) else x.split(', '))\n",
    "\n",
    "    # convert each author name to lowercase\n",
    "    df['coauthors'] = df['coauthors'].apply(lambda x: [name.lower() for name in x])\n",
    "\n",
    "    # replace NaN values with 'journal not found' in 'journal'\n",
    "    df['journal'] = df['journal'].apply(lambda x: 'journal not found' if pd.isna(x) else x)\n",
    "\n",
    "    # drop rows where 'abstract' is 'abstract not found' \n",
    "    df = df[df['paper_abstract'] != 'abstract not found']\n",
    "\n",
    "    # drop rows where 'abstract' has fewer than 20 words \n",
    "    df = df[df['paper_abstract'].astype(str).str.split().apply(len) >= 20]\n",
    "\n",
    "    # replace missing values in 'total_citation' with 0\n",
    "    df['paper_total_citations'] = df['paper_total_citations'].fillna(0) \n",
    "\n",
    "    # replace missing values in yearly citation columns with 0\n",
    "    for year in range(2001, 2025):\n",
    "        df[f'citation_{year}'] = df[f'citation_{year}'].fillna(0)\n",
    "\n",
    "    # assign data types to 'award_year' and 'publication_year'\n",
    "    df['award_year'] = pd.to_numeric(df['award_year'], errors='coerce')\n",
    "    df['award_year'] = df['award_year'].astype('int64').astype('category')\n",
    "    df['publication_year'] = pd.to_numeric(df['publication_year'], errors='coerce')\n",
    "    df['publication_year'] = df['publication_year'].astype('int64').astype('category')\n",
    "\n",
    "    # assign data types to the rest columns\n",
    "    columns = {f'citation_{year}': 'int64' for year in range(2001, 2025)}\n",
    "    df = df.astype({'first_name': 'object', 'middle_name': 'object', 'last_name': 'object', 'email': 'object', 'institution': 'category', \n",
    "                    'award_amount': 'int64', 'paper_title': 'object', 'journal': 'category', 'coauthors': 'object', 'paper_abstract': 'object', \n",
    "                    'paper_total_citations': 'int64'} | columns)\n",
    "\n",
    "    # reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # save the dataframe to a csv file\n",
    "    df.to_csv(save_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(load_file_path = 'database/cleaned_content_analysis.csv', save_file_path = 'database/preprocessed_content_analysis.csv'):\n",
    "    '''\n",
    "    This function preprocesses a pandas DataFrame.\n",
    "    \n",
    "    Inputs:\n",
    "        load_file_path: file path to load original CSV file\n",
    "        save_file_path: file path to save cleaned CSV file\n",
    "    '''\n",
    "    \n",
    "    # load the CSV file to a DataFrame\n",
    "    df = pd.read_csv(load_file_path, index_col=0)\n",
    "    \n",
    "    # tokenize 'title' column\n",
    "    df['tokenized_title'] = df['paper_title'].progress_apply(lambda x: [lucem_illud.word_tokenize(s) for s in lucem_illud.sent_tokenize(x)])\n",
    "    \n",
    "    # normalize 'tokenized_title' column\n",
    "    df['normalized_title'] = df['tokenized_title'].apply(lambda x: [lucem_illud.normalizeTokens(s) for s in x])\n",
    "    \n",
    "    # tokenize 'abstract' column\n",
    "    df['tokenized_abstract'] = df['paper_abstract'].progress_apply(lambda x: [lucem_illud.word_tokenize(s) for s in lucem_illud.sent_tokenize(x)])\n",
    "    \n",
    "    # nomalize 'tokenized_abstract' column\n",
    "    df['normalized_abstract'] = df['tokenized_abstract'].apply(lambda x: [lucem_illud.normalizeTokens(s) for s in x])\n",
    "\n",
    "    # save the dataframe to a csv file\n",
    "    df.to_csv(save_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
